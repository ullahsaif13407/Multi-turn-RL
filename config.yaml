model:
  name: Qwen/Qwen3-1.7B
  max_length: 4096
  dtype: bfloat16
  lora_r: 16
  lora_alpha: 32

data:
  dataset: gsm8k
  max_samples: 1000
  split: train

generation:
  max_tool_rounds: 5
  max_new_tokens: 512
  temperature: 0.7
  enable_thinking: true

training:
  lr: 1.0e-5
  batch_size: 4
  num_iterations: 100
  group_size: 4
  kl_coef: 0.1
  max_turns: 10
  max_grad_norm: 1.0

rewards:
  success: 1.0
  failure: -1.0
  turn_penalty: -0.1

# wandb:
#   enabled: true
#   project: multi-turn-rl
